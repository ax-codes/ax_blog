---
title: Scrapy学习篇(一)-项目框架
date: 2018/01/16 20:00:00
categories: 技术
toc: True
tags: [python]
---


### 前言
Scrapy 是用 Python 实现的一个为了爬取网站数据、提取结构性数据而编写的应用框架
Scrapy 常应用在包括数据挖掘,信息处理或存储历史数据等一系列的程序中
通常我们可以很简单的通过 Scrapy 框架实现一个爬虫,抓取指定网站的内容或图片
Scrapy官网文档:https://doc.scrapy.org/en/latest/

### 框架图示
![1.jpg ](1.jpg)

### 框架组件
Scrapy Engine(引擎): 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯,信号、数据传递等.
Scheduler(调度器): 它负责接受引擎发送过来的Request请求,并按照一定的方式进行整理排列,入队,当引擎需要时,交还给引擎.
Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求,并将其获取到的Responses交还给Scrapy Engine(引擎),由引擎交给Spider来处理.
Spider（爬虫）：它负责处理所有Responses,从中分析提取数据,获取Item字段需要的数据,并将需要跟进的URL提交给引擎,再次进入Scheduler(调度器).
Item Pipeline(管道)：它负责处理Spider中获取到的Item,并进行进行后期处理（详细分析、过滤、存储等）的地方.
Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件.
Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）.

#### 数据流向
引擎从Spider中获取到初始Requests.
引擎将从Spider获取到的Requests放入调度器,并请求下一个要爬取的Requests.
调度器返回下一个要爬取的Requests给引擎
引擎将Requests通过下载器中间件转发给下载器(Downloader).
一旦页面下载完毕,下载器生成一个该页面的Response,并将其通过下载中间件(返回(response)方向)发送给引擎.
引擎从下载器中接收到Response并通过Spider中间件(输入方向)发送给Spider处理.
Spider处理Response并返回爬取到的Item及(跟进的)新的Request给引擎.
引擎将(Spider返回的)爬取到的Item交给ItemPipeline处理,将(Spider返回的)Request交给调度器,并请求下一个Requests（如果存在的话）.
(从第一步)重复直到调度器中没有更多地Request.


### 总结
一般我们的业务逻辑主要集中在spider的request的创建response的处理,item的实例化和使用pipeline的数据存储
